{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proposed_method.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chbCrPHyNHz1"
      },
      "source": [
        "#Download the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epgol2GrM5jE"
      },
      "source": [
        "# First Download the dataset to the same directory "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dtp8NR_PFIl"
      },
      "source": [
        "#Preprocessing of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzxyVdAtCV64"
      },
      "source": [
        "import glob\n",
        "import numpy as npn\n",
        "from osgeo import gdal\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def bandstoarray(ds):\n",
        "    band1 = ds.GetRasterBand(1) # Red channel \n",
        "    band2 = ds.GetRasterBand(2) # Green channel \n",
        "    band3 = ds.GetRasterBand(3) # Blue channel\n",
        "\n",
        "\n",
        "    b1 = band1.ReadAsArray() \n",
        "    b2 = band2.ReadAsArray() \n",
        "    b3 = band3.ReadAsArray() \n",
        "\n",
        "\n",
        "    rgb = np.dstack((b1,b2,b3))\n",
        "\n",
        "\n",
        "    rgb_pixel=tf.reshape(rgb, (rgb.shape[0]*rgb.shape[1], 3))\n",
        "\n",
        "    return rgb_pixel\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Create_dataset(path_file_rgb,glob_file_rgb,path_file_B567,glob_file_B567):\n",
        "    n=0\n",
        "\n",
        "    \n",
        "    nfiles=len(sorted(glob.glob(glob_file_rgb)))\n",
        "    print(\"Number of files\",nfiles)\n",
        "\n",
        "    for num in range(nfiles):  # range(nfiles)\n",
        "        \n",
        "        path_name_rgb=path_file_rgb.format(num)\n",
        "        ds_rgb = gdal.Open(path_name_rgb)\n",
        "\n",
        "        path_name_B567=path_file_B567.format(num)\n",
        "        ds_B567 = gdal.Open(path_name_B567)\n",
        "\n",
        "\n",
        "        if (ds_rgb.RasterCount==3):\n",
        "            \n",
        "\n",
        "            RGB=bandstoarray(ds_rgb)\n",
        "\n",
        "            B567=bandstoarray(ds_B567)\n",
        "\n",
        "\n",
        "            Total=np.concatenate([RGB, B567], axis=1)\n",
        "\n",
        "            np.random.shuffle(Total)\n",
        "            np.random.shuffle(Total)\n",
        "            np.random.shuffle(Total)\n",
        "  \n",
        "\n",
        "\n",
        "            n_of_rows = Total.shape[0]\n",
        "\n",
        "            n_indices = np.random.choice(n_of_rows, size=50, replace=False)#50 samples\n",
        "\n",
        "            random_rows = Total[n_indices, :]\n",
        "\n",
        "\n",
        "            if (n == 0):\n",
        "                \n",
        "                B_T=random_rows\n",
        "                \n",
        "\n",
        "\n",
        "            else:\n",
        "\n",
        "\n",
        "                Prev= B_T\n",
        "\n",
        "                B_T=np.concatenate([Prev,random_rows], axis=0)\n",
        "            \n",
        "            n=n+1\n",
        "\n",
        "            output.clear()\n",
        "            print(\"Files completed \",n)\n",
        "\n",
        "\n",
        "\n",
        "         \n",
        "\n",
        "\n",
        "   \n",
        "    print(\"Parameters rgb_pixel\",B_T.shape)\n",
        "    \n",
        "\n",
        "    return n ,B_T\n",
        "    \n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL3Ob3wEDyWS",
        "outputId": "51832087-770a-4b99-c8c1-740171789944"
      },
      "source": [
        "path_file_1=\"/content/Atmo_corr/Train/RGB/RGB_{}.tif\" \n",
        "glob_file_1=\"/content/Atmo_corr/Train/RGB/RGB_*.tif\" \n",
        "\n",
        "path_file_2=\"/content/Atmo_corr/Train/B567/TAR_{}.tif\" \n",
        "glob_file_2=\"/content/Atmo_corr/Train/B567/TAR_*.tif\" \n",
        "\n",
        "n1,All_train=Create_dataset(path_file_1,glob_file_1,path_file_2,glob_file_2)\n",
        "print('number of training  samples: ', All_train.shape)\n",
        "\n",
        "\n",
        "# shuffle for several times : dataset is so large \n",
        "np.random.shuffle(All_train)\n",
        "np.random.shuffle(All_train)\n",
        "np.random.shuffle(All_train)\n",
        "np.random.shuffle(All_train)\n",
        "np.random.shuffle(All_train)\n",
        "\n",
        "\n",
        "X=All_train[:,[0,1,2]]\n",
        "Y=All_train[:,[3,4,5]]\n",
        "\n",
        "\n",
        "print(X.shape,Y.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files completed  18370\n",
            "Parameters rgb_pixel (918500, 6)\n",
            "number of training  samples:  (918500, 6)\n",
            "(918500, 3) (918500, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPV_fBbcxPd1",
        "outputId": "dceb99c3-56d0-46f8-9cec-5830d6cc1cb3"
      },
      "source": [
        "# Prepare it for deep learning model \n",
        "\n",
        "X=np.reshape(X, (X.shape[0],1,X.shape[1]))\n",
        "\n",
        "Y=np.reshape(Y, (Y.shape[0],1,Y.shape[1]))\n",
        "\n",
        "print(X.shape,Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(918500, 1, 3) (918500, 1, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5040maj3NV5l"
      },
      "source": [
        "#The proposed model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hTxAS3pyWua",
        "outputId": "e5e11fa0-8398-4d82-ec3c-6b40c04cacc0"
      },
      "source": [
        "from tensorflow.python.keras.layers import  Lambda,Conv1D, Activation\n",
        "from tensorflow.python import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "def Conv_block(x_in, IN,filters):\n",
        "    \n",
        "    x1 = Conv1D(filters, 3,activation='relu',padding='same')(x_in)        \n",
        "\n",
        "    x3 = Conv1D(filters, 3,padding='same')(x1) \n",
        "\n",
        "\n",
        "    X_T = tf.keras.layers.concatenate([x3,IN])\n",
        "\n",
        "    return X_T\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Variant_model():\n",
        "\n",
        "    inputs = keras.Input(shape=(1,3))  \n",
        "\n",
        "    Y0=Conv_block(inputs,inputs,8)\n",
        "    Y1=Conv_block(Y0,inputs,16)\n",
        "    Y2=Conv_block(Y1,inputs,32)\n",
        "    Y3=Conv_block(Y2,inputs,64)\n",
        "    Y4=Conv_block(Y3,inputs,64)\n",
        "    Y5=Conv_block(Y4,inputs,128)\n",
        "   \n",
        "\n",
        "    Out = Conv1D(3, 3,padding='same')(Y5)\n",
        "    \n",
        "\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=Out, name=\"COM\")\n",
        "\n",
        "\n",
        "COM=Variant_model()\n",
        "\n",
        "COM.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"COM\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1, 3)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 1, 8)         80          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 1, 8)         200         conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1, 11)        0           conv1d_1[0][0]                   \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 1, 16)        544         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 1, 16)        784         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1, 19)        0           conv1d_3[0][0]                   \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 1, 32)        1856        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 1, 32)        3104        conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1, 35)        0           conv1d_5[0][0]                   \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 1, 64)        6784        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 1, 64)        12352       conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 1, 67)        0           conv1d_7[0][0]                   \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 1, 64)        12928       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 1, 64)        12352       conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 1, 67)        0           conv1d_9[0][0]                   \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 1, 128)       25856       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 1, 128)       49280       conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 1, 131)       0           conv1d_11[0][0]                  \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, 1, 3)         1182        concatenate_5[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 127,302\n",
            "Trainable params: 127,302\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x4XIcZmORxt"
      },
      "source": [
        "#Training process\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avaGMzMnhq_A"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "\n",
        "checkpoint_filepath = '/content/checkpoint'\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "Adam = optimizers.Adam(lr=0.001)  \n",
        "COM.compile(optimizer=Adam, loss='mse')\n",
        "\n",
        "history1=COM.fit(X,Y,validation_split=0.2,batch_size=256,callbacks=[model_checkpoint_callback],epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9D6rDLjQt89"
      },
      "source": [
        "#Save model \n",
        "COM.save(\"my_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPXzujq_Ql-u"
      },
      "source": [
        "#Apply for test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm91gbxSQpYt"
      },
      "source": [
        "from tensorflow import keras\n",
        "#!unzip my_model.zip     \n",
        "\n",
        "reconstructed_model = keras.models.load_model(\"my_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlMR8kgxQ4mV"
      },
      "source": [
        "#install some libraries \n",
        "!pip install hdf5storage\n",
        "!pip install image-similarity-measures\n",
        "import image_similarity_measures\n",
        "from image_similarity_measures.quality_metrics import  psnr,sam,ssim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V1JEh3rROjV"
      },
      "source": [
        "##Preprocess Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDc5FcWbDgZL"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import hdf5storage\n",
        "def Test_bandstoarray(ds):\n",
        "    band1 = ds.GetRasterBand(1) # Red channel \n",
        "    band2 = ds.GetRasterBand(2) # Green channel \n",
        "    band3 = ds.GetRasterBand(3) # Blue channel\n",
        "\n",
        "\n",
        "    b1 = band1.ReadAsArray()  \n",
        "    b2 = band2.ReadAsArray() \n",
        "    b3 = band3.ReadAsArray() \n",
        "\n",
        "           \n",
        "    rgb = np.dstack((b1,b2,b3))\n",
        "\n",
        "\n",
        "    return rgb\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def batch_RMSE(im_true, im_fake, data_range=255.):\n",
        "\n",
        "    im_true=torch.from_numpy(np.array(im_true))\n",
        "    im_fake=torch.from_numpy(np.array(im_fake))\n",
        "\n",
        "    #print(\"Tensor size \",im_true.size())\n",
        "\n",
        "    N = im_true.size()[0]\n",
        "    C = im_true.size()[1]\n",
        "    H = im_true.size()[2]\n",
        "    W = im_true.size()[3]\n",
        "    Itrue = im_true.clamp(0.,1.).mul_(data_range).resize_(N, C*H*W)\n",
        "    Ifake = im_fake.clamp(0.,1.).mul_(data_range).resize_(N, C*H*W)\n",
        "    mse = nn.MSELoss(reduce=False)\n",
        "    err = mse(Itrue, Ifake).sqrt_().sum(dim=1, keepdim=True).div_(C*H*W)\n",
        "    return torch.mean(err)\n",
        "\n",
        "\n",
        "def batch_rRMSE(im_true, im_fake, data_range=255.):\n",
        "    im_true=torch.from_numpy(np.array(im_true))\n",
        "    im_fake=torch.from_numpy(np.array(im_fake))\n",
        "\n",
        "    N = im_true.size()[0]\n",
        "    C = im_true.size()[1]\n",
        "    H = im_true.size()[2]\n",
        "    W = im_true.size()[3]\n",
        "    Itrue = im_true.clamp(0.,1.).mul_(data_range).resize_(N, C*H*W)\n",
        "    Ifake = im_fake.clamp(0.,1.).mul_(data_range).resize_(N, C*H*W)\n",
        "    mse = nn.MSELoss(reduce=False)\n",
        "    err = mse(Itrue, Ifake).sqrt_().div_(Itrue).sum(dim=1, keepdim=True).div_(C*H*W)\n",
        "    return torch.mean(err)\n",
        "\n",
        "\n",
        "def reformulate(X):\n",
        "     PR = np.expand_dims(X, axis=0)\n",
        "     #print(PR.shape)\n",
        "     PR=  np.transpose(PR, [0,3,1,2])\n",
        "     #print(PR.shape)\n",
        "  \n",
        "     return PR\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def apply_test(path_file_rgb,glob_file_rgb,path_file_B567,glob_file_B567,reconstructed_model):\n",
        "    n=0\n",
        "    RMSE=0\n",
        "    rRMSE=0\n",
        "    SAM=0\n",
        "    PSNR=0\n",
        "    SSIM=0\n",
        "\n",
        "    \n",
        "    nfiles=len(sorted(glob.glob(glob_file_rgb)))\n",
        "    print(\"Number of files\",nfiles)\n",
        "    mycount=0\n",
        "\n",
        "    ND=20  # Change the values   nfiles\n",
        "\n",
        "    SM = np.zeros(ND)\n",
        "    SM1 = np.zeros(ND)\n",
        "    ps1 = np.zeros(ND)\n",
        "    ps2 = np.zeros(ND)\n",
        "    for num in range(ND):  # range(nfiles)\n",
        "        print(num)\n",
        "        mycount=mycount+1\n",
        "        path_name_rgb=path_file_rgb.format(num)\n",
        "        ds_rgb = gdal.Open(path_name_rgb)\n",
        "\n",
        "        path_name_B567=path_file_B567.format(num)\n",
        "        ds_B567 = gdal.Open(path_name_B567)\n",
        "\n",
        "        RGB=Test_bandstoarray(ds_rgb)\n",
        "\n",
        "        B567=Test_bandstoarray(ds_B567)\n",
        "\n",
        "        \n",
        "        # Predict   \n",
        "        \n",
        "        RGB_predict=tf.reshape(RGB, (RGB.shape[0]*RGB.shape[1],1, 3))\n",
        "\n",
        "        B567_predictd=reconstructed_model.predict(RGB_predict)\n",
        "\n",
        "        B567_predictd=np.reshape(B567_predictd, (RGB.shape[0],RGB.shape[1], 3))  # tf \n",
        "\n",
        "        B567_predictd=np.clip(B567_predictd, 0, 1)\n",
        "        B567=np.clip(B567, 0, 1)\n",
        "\n",
        "        psnr2 = tf.image.psnr(B567_predictd, B567, max_val=1.0)\n",
        "        #print(psnr2)\n",
        "        SM1[num]=sam(B567,B567_predictd)\n",
        "        ps1[num]=psnr(B567,B567_predictd,max_p=1 )\n",
        "        ps2[num]=psnr2\n",
        "        # add other metrics \n",
        "        PR=reformulate(B567_predictd)\n",
        "        OR=reformulate(B567)\n",
        "\n",
        "        RMSE = RMSE+batch_RMSE(OR, PR)\n",
        "\n",
        "\n",
        "        rRMSE = rRMSE+batch_rRMSE(OR, PR)\n",
        "\n",
        "        SAM = SAM+sam(B567,B567_predictd)\n",
        "\n",
        "        PSNR=PSNR+psnr(B567,B567_predictd,max_p=1)\n",
        "\n",
        "        SSIM=SSIM+ssim(B567,B567_predictd,max_p=1)\n",
        "\n",
        "\n",
        "\n",
        "    return RMSE/mycount,rRMSE/mycount , SAM/mycount,PSNR/mycount,SSIM/mycount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbZBS3mdDIHk",
        "outputId": "c5fd3c34-58bf-4280-ae77-b41d28f1e6b2"
      },
      "source": [
        "\n",
        "path_file_1=\"/content/Atmo_corr/Test/RGB/RGB_{}.tif\" \n",
        "glob_file_1=\"/content/Atmo_corr/Test/RGB/RGB_*.tif\" \n",
        "\n",
        "path_file_2=\"/content/Atmo_corr/Test/B567/TAR_{}.tif\" \n",
        "glob_file_2=\"/content/Atmo_corr/Test/B567/TAR_*.tif\" \n",
        "\n",
        "n1,n2,n3,n4,n5=apply_test(path_file_1,glob_file_1,path_file_2,glob_file_2,reconstructed_model)\n",
        "\n",
        "print(\"RMSE\",n1,\"rRMSE\",n2,\"SAM\",n3,\"PSNR\",n4,\"SSIM\",n5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of files 5207\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "RMSE tensor(5.2431) rRMSE tensor(0.0845) SAM 2.88199103474617 PSNR 31.969075202941895 SSIM 0.8941062025041651\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}